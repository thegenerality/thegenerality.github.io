<!DOCTYPE html>
<html lang="en">

<head>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-71156606-1');
    </script>
    <meta charset="utf-8" />
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Furu Wei's Homepage</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <link rel="stylesheet" type="text/css" href="./assets/css/main.css" />

    <script type="text/javascript">document.documentElement.className = 'js';</script>
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta property="og:type" content="website" />
    
    <meta property="og:image:width" content="3200" />
    <meta property="og:image:height" content="1800" />

    <meta name="generator" content="Ghost 5.12" />
    <style id="gh-members-styles">
        .gh-post-upgrade-cta-content,
        .gh-post-upgrade-cta {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            text-align: center;
            width: 100%;
            color: #ffffff;
            font-size: 16px;
        }

        .gh-post-upgrade-cta-content {
            border-radius: 8px;
            padding: 40px 4vw;
        }

        .gh-post-upgrade-cta h2 {
            color: #ffffff;
            font-size: 28px;
            letter-spacing: -0.2px;
            margin: 0;
            padding: 0;
        }

        .gh-post-upgrade-cta p {
            margin: 20px 0 0;
            padding: 0;
        }

        .gh-post-upgrade-cta small {
            font-size: 16px;
            letter-spacing: -0.2px;
        }

        .gh-post-upgrade-cta a {
            color: #ffffff;
            cursor: pointer;
            font-weight: 500;
            box-shadow: none;
            text-decoration: underline;
        }

        .gh-post-upgrade-cta a:hover {
            color: #ffffff;
            opacity: 0.8;
            box-shadow: none;
            text-decoration: underline;
        }

        .gh-post-upgrade-cta a.gh-btn {
            display: block;
            background: #ffffff;
            text-decoration: none;
            margin: 28px 0 0;
            padding: 8px 18px;
            border-radius: 4px;
            font-size: 16px;
            font-weight: 600;
        }

        .gh-post-upgrade-cta a.gh-btn:hover {
            opacity: 0.92;
        }
    </style>
    <script defer src="./assets/js/cards.min.js"></script>
    <style>
        :root {
            --ghost-accent-color: #15171A;
        }
    </style>
    <link rel="stylesheet" type="text/css" href="./assets/css/cards.min.css">
</head>

<body>

    <header>
        <nav class="nav container" data-url="/blog/">
            <div class="nav-row row align-items-center">
                <div class="d-none d-sm-block col-sm nav-symbol-wrap" style="padding-top:5px">
                    <a href="#"><h2> Furu Wei </h2></a> <div class="main" style="font-size:12pt;">
    @ <a href="https://www.microsoft.com/en-us/research/people/fuwei/" target="_blank">Microsoft Reserach</a> | <a href="http://scholar.google.com/citations?user=G-V1VpwAAAAJ&hl=en" target="_blank">Google Scholar</a> | <a href="https://www.linkedin.com/in/weifuru/" target="_blank">LinkedIn</a>
        </div>
                </div>
                
        
                <div class="col col-sm-auto">
                    <ul class="d-flex flex-row align-items-center justify-content-between small-caps">
                        <div class="d-sm-none nav-symbol-wrap">
                        </div>

                        <li class="ml-sm-1.75" style="margin-top:0.5px"><a class="nav-link" href="https://scholar.google.com/citations?hl=en&user=G-V1VpwAAAAJ&view_op=list_works&sortby=pubdate"
                            data-slug="research">Research</a></li>
                    </ul>
                </div>
            </div>
        </nav>

    </header>
    <div class="container mt-4" style="font-size:14pt; text-align:justify">
        <p>Dr. Furu Wei is a Partner Research Manager (全球研究合伙人) at Microsoft Research Asia, where he leads and oversees research on Foundation Models (across tasks, languages and modalities), NLP, MT, Speech and Multimodal AI. More recently, he has also been driving the mission-focused research on General AI, focusing on fundamental research of the Foundation of A(G)I. Furu received his B.S. and Ph.D. in computer science from Wuhan University in 2004 and 2009, respectively. He was a Staff Researcher at IBM Research - China (IBM CRL) from Jul. 2009 to Nov. 2010, and a Research Assistant at Department of Computing, The Hong Kong Polytechnic University from Jan. 2007 to Jun. 2009.
</p>
        
        <br>

    <p>Furu published over 200 research papers in prestigious conferences and journals in natural language processing and artificial intelligence, including ACL, EMNLP, NAACL, COLING, Computational Linguistics, ICML, NeurIPS, ICLR, SIGIR, KDD, AAAI, IJCAI, etc. According to <a href="http://scholar.google.com/citations?user=G-V1VpwAAAAJ&hl=en" target="_blank"><font color="blue">Google Scholar</font></a>, his H-index is 90 with more than 40,000 citations (as of 2024). As a co-author, Furu received the Best Paper Runners Up award at AAAI 2021, and the Best Student Paper award at KDD 2018. Furu served as a Senior Area Chair in ACL 2021, an Area Chair in EMNLP 2015, NAACL-HIT 2016, EMNLP 2019, and NeurIPS 2021. He has more than 20 patents filed or granted. The research from Furu and his team has been widely integrated in Microsoft products, including Office (Word, PowerPoint, Outlook and Microsoft Designer), Bing, Microsoft Ads, Azure (Cognitive Services), Dynamics, Windows, LinkedIn, etc. </p>
    
        <br>
        
    <p>Recently, Furu has been driving the agenda of the mission-focused research on advancing A(G)I for humanity, focusing on fundamental research of the <b>Foundation of A(G)I</b>. We are also committed to building the <i>new foundation of A(G)I</i>.
    
    <div style="padding-left:20px; padding-top:10px">
    Our research has been pushing <b>#TheBigConvergence</b> of <i>Foundation Models</i> across tasks, languages, and modalities, including <font color="blue">UniLM</font>(-2) for language; InfoXLM, <font color="blue">XLM-E</font> for multilingual; <font color="blue">BEiT</font>(-2) for vision; WavLM, SpeechLM, <font color="blue">VALL-E</font> for speech; <font color="blue">BEiT-3</font> for multimodal; <font color="blue">Layout(X)LM(-2/3)</font> as the multimodal document foundation model; <font color="blue">MetaLM</font> as the general-purpose foundation model; <b>The Evolution of (M)LLMs</b> (<b>Multimodal LLMs</b>):  <font color="red">Kosmos-1/2/2.5/G</font>, <font color="red">VALL-E</font>.
    </div>
    
    <div style="padding-left:20px; padding-top:10px">
    Our research on <i>Foundation Architecture</i> has been pushing new architectures for foundation models and A(G)I, focusing on modeling generality and capability, as well as training stability and efficiency, including <font color="blue">DeepNet</font> (training stability), <font color="blue">Magneto</font> (modeling generality), <font color="blue">Multiway Transformers</font> (multimodal modeling), X-MoE (efficiency), <font color="blue">LEX Transformer</font> (better position embedding and length extrapolation), <b>The Revolution of Model Architecture</b>: <font color="red">RetNet</font>, <font color="red">BitNet</font>, <font color="red">LongNet</font>, and <font color="red">TorchScale</font> (<b>Library</b>). 
    </div>
    
    <div style="padding-left:20px; padding-top:10px">
    <i>Science of Intelligence</i>: Understanding the principles and theoretical boundary of (artificial general) intelligence. <a href="https://arxiv.org/abs/2212.10559" target=_blank><font color="blue">Why Can GPT Learn In-Context?</font></a>.
    </div>
    
    <div style="padding-left:20px; padding-top:10px">
    <i>LLMOps</i>: Research and technology for building AI products w/ foundation models. We work on general technology for <b>enabling AI capabilities w/ (M)LLMs</b>, including <font color="red">MiniLLM</font> (LLM Distillation), <font color="blue">LLM Accelerator</font>, <font color="blue">Structured Prompting</font>, Extensible Prompts, and Promptist. We also develop effective and efficient approaches to deploying large AI models in practice, including <font color="blue">MiniLM</font>(-2), <font color="blue">xTune</font>, EdgeFormer, and <font color="blue">Aggressive Decoding</font>.
    </div>
    
    <br>
    In addition to the research achievements, these models are significant parts of Microsoft's own family of large AI (foundation) models powering language and multimodal tasks and scenarios across products in Microsoft. Moreover, our research tops public benchmarks and leaderboards across language, vision, speech, and multimodal tasks, and hugely contributes to the open source community through GitHub and Hugging Face.
    </p>
    
    <br>
    
    <p style="margin-top:0px;">Furu Wei was named to the first (2017) MIT Technology Review’s annual list of Innovators Under 35 China (<i>MIT TR35 China</i>) for contributions to natural language processing. </p>
        <br>
        
        <p>
            We are hiring at all levels (including FTE researchers and interns)! If you are interested in working with us on Foundation Models and General AI, NLP, MT, Speech, Document AI and Multimodal AI, 
            please send your resume to <a href = "mailto: fuwei@microsoft.com"><u>fuwei@microsoft.com</u></a>.
        </p>
        <br>
        
        <p> <a href="https://github.com/microsoft/unilm" target="_blank"><font color="blue">microsoft/unilm</font>: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities</a> </p>
        <p> <a href="https://github.com/microsoft/torchscale" target="_blank"><font color="blue">microsoft/torchscale</font>: Neural Architecture for General AI</a> </p>
        <p> <a href="https://github.com/microsoft/LMOps" target="_blank"><font color="blue">microsoft/lmops</font>: General technology for enabling AI capabilities w/ (M)LLMs</a> </p>
        <br>
        <p> Our mission-focused research on <a href="agi/" target="_blank"><font color="blue">Advancing A(G)I for humanity | Foundation of A(G)I</font></a></p> <!--: On the Generality, Generalizability, and Adaptability of AI-->
        
    </div>
    
    
    <footer class="footer container medium-xsmall-copy line-height-1.6">

        <div class="row align-items-center mb-0.125">
            <div class="col-12 col-md mb-0.5">
                <a class="fade" style="margin-top:1px" href="/">&copy; 2022</a>
            </div>
        </div>
    </footer>

    <script type="text/javascript" src="./assets/js/main.min.js"></script>


</body>

</html>
